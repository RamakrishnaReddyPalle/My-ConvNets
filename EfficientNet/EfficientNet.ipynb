{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stochdepth in d:\\anaconda\\envs\\yolov7_env\\lib\\site-packages (0.5.0)\n",
      "Requirement already satisfied: torch>=1.8 in d:\\anaconda\\envs\\yolov7_env\\lib\\site-packages (from stochdepth) (2.3.0)\n",
      "Requirement already satisfied: torchvision>=0.9 in d:\\anaconda\\envs\\yolov7_env\\lib\\site-packages (from stochdepth) (0.18.0)\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\envs\\yolov7_env\\lib\\site-packages (from torch>=1.8->stochdepth) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in d:\\anaconda\\envs\\yolov7_env\\lib\\site-packages (from torch>=1.8->stochdepth) (4.11.0)\n",
      "Requirement already satisfied: sympy in d:\\anaconda\\envs\\yolov7_env\\lib\\site-packages (from torch>=1.8->stochdepth) (1.12)\n",
      "Requirement already satisfied: networkx in d:\\anaconda\\envs\\yolov7_env\\lib\\site-packages (from torch>=1.8->stochdepth) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda\\envs\\yolov7_env\\lib\\site-packages (from torch>=1.8->stochdepth) (3.1.4)\n",
      "Requirement already satisfied: fsspec in d:\\anaconda\\envs\\yolov7_env\\lib\\site-packages (from torch>=1.8->stochdepth) (2024.6.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in d:\\anaconda\\envs\\yolov7_env\\lib\\site-packages (from torch>=1.8->stochdepth) (2021.4.0)\n",
      "Requirement already satisfied: numpy in d:\\anaconda\\envs\\yolov7_env\\lib\\site-packages (from torchvision>=0.9->stochdepth) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\anaconda\\envs\\yolov7_env\\lib\\site-packages (from torchvision>=0.9->stochdepth) (9.5.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in d:\\anaconda\\envs\\yolov7_env\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.8->stochdepth) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in d:\\anaconda\\envs\\yolov7_env\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.8->stochdepth) (2021.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anaconda\\envs\\yolov7_env\\lib\\site-packages (from jinja2->torch>=1.8->stochdepth) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\anaconda\\envs\\yolov7_env\\lib\\site-packages (from sympy->torch>=1.8->stochdepth) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install stochdepth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from stochastic_depth import StochasticDepth\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConvBlock\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, groups=1, act=True, bias=False):\n",
    "        super().__init__()\n",
    "        \"\"\" If k = 1 -> p = 0, k = 3 -> p = 1, k = 5, p = 2. \"\"\"\n",
    "        padding = kernel_size // 2\n",
    "        self.c = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias, groups=groups)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.silu = nn.SiLU() if act else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.silu(self.bn(self.c(x)))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Squeeze-and-Excitation Block\n",
    "class SeBlock(nn.Module):\n",
    "    def __init__(self, in_channels, r):\n",
    "        super().__init__()\n",
    "        C = in_channels\n",
    "        self.globpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc1 = nn.Linear(C, C//r, bias=False)\n",
    "        self.fc2 = nn.Linear(C//r, C, bias=False)\n",
    "        self.silu = nn.SiLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\" x shape: [N, C, H, W]. \"\"\" \n",
    "        f = self.globpool(x)\n",
    "        f = torch.flatten(f,1)\n",
    "        f = self.silu(self.fc1(f))\n",
    "        f = self.sigmoid(self.fc2(f))\n",
    "        f = f[:,:,None,None]\n",
    "        \"\"\" f shape: [N, C, 1, 1] \"\"\" \n",
    "\n",
    "        scale = x * f\n",
    "        return scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MBConv\n",
    "class MBConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, exp, r):\n",
    "        super().__init__()\n",
    "        exp_channels = in_channels * exp\n",
    "        self.add = in_channels == out_channels and stride == 1\n",
    "        self.c1 = ConvBlock(in_channels, exp_channels, 1, 1) if exp > 1 else nn.Identity()\n",
    "        self.c2 = ConvBlock(exp_channels, exp_channels, kernel_size, stride, exp_channels)\n",
    "        self.se = SeBlock(exp_channels, r)\n",
    "        self.c3 = ConvBlock(exp_channels, out_channels, 1, 1, act=False)\n",
    "\n",
    "        \" Stochastic Depth module with default survival probability 0.5. \"\n",
    "        self.sd = StochasticDepth()\n",
    "\n",
    "    def forward(self, x):\n",
    "        f = self.c1(x)\n",
    "        f = self.c2(f)\n",
    "        f = self.se(f)\n",
    "        f = self.c3(f)\n",
    "\n",
    "        if self.add:\n",
    "            f = x + f\n",
    "\n",
    "        f = self.sd(f)\n",
    "\n",
    "        return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classfier\n",
    "class Classifier(nn.Module):\n",
    "    \"\"\" Last stage with Average Pooling and Fully-Connected layer. \"\"\" \n",
    "    def __init__(self, in_channels, classes, p):\n",
    "        super().__init__()\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(in_channels, classes)\n",
    "        self.dropout = nn.Dropout(p)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(self.pool(x))\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EfficientNet\n",
    "class EfficientNet(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        model_config : str,\n",
    "        in_channels : int = 3, \n",
    "        classes : int = 1000,\n",
    "        show : str = False\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.show = show # if True print the output dim between layers \n",
    "        config = Config()\n",
    "        stages = config.stages\n",
    "        phis = config.phis[model_config]\n",
    "\n",
    "        \"\"\" Parameters. \"\"\"\n",
    "        phi, res, p = phis\n",
    "        self._calculate_coef(phi)\n",
    "\n",
    "        \"\"\" Network. \"\"\"\n",
    "        self.net = nn.ModuleList([])\n",
    "        self.channels = []\n",
    "\n",
    "        \"\"\" First stage Conv3x3. \"\"\"\n",
    "        f, c, l, k, s, exp = stages[0]\n",
    "        self._add_layer(3, f, c, l, k, s)\n",
    "\n",
    "        \"\"\" 2-8 stages with MBConvs. \"\"\"\n",
    "        for i in range(1, len(stages)-1):\n",
    "            if i == 1:\n",
    "                r = 4\n",
    "            else:\n",
    "                r = 24\n",
    "\n",
    "            f, c, l, k, s, exp = stages[i]\n",
    "            self._add_layer(self.channels[-1], f, c, l, k, s, exp, r)\n",
    "\n",
    "        \"\"\" Last stage Conv1x1 + Classifier. \"\"\"\n",
    "        f, c, l, k, s, exp = stages[-1]\n",
    "        self._add_layer(self.channels[-1], f, c, l, k, s)\n",
    "        self.net.append(Classifier(self.channels[-1], classes, p))\n",
    "\n",
    "    def forward(self, x):\n",
    "        ''' Fancy way to print shapes of certain stages. '''\n",
    "        i = 1\n",
    "        for F in self.net:\n",
    "            in_feat, h, w = x.shape[1:]\n",
    "\n",
    "            x = F(x)\n",
    "            if in_feat != x.shape[1] and i < 10:\n",
    "                if self.show : print(\"Stage {} -> \".format(i), [x.shape[1], h, w])\n",
    "                i += 1\n",
    "        return x\n",
    "\n",
    "    def _add_layer(self, in_channels, f, c, l, k, s, *args):\n",
    "        c, l = self._update_feat(c, l)\n",
    "        if l == 1:\n",
    "            self.net.append(f(in_channels, c, k, s, *args))\n",
    "        else:\n",
    "            \"\"\" First layer with stride 1. \"\"\"\n",
    "            self.net.append(f(in_channels, c, k, 1, *args))\n",
    "            \n",
    "            \"\"\" Another layers with stride 1. \"\"\"\n",
    "            for _ in range(l-2):\n",
    "                self.net.append(f(c, c, k, 1, *args))                \n",
    "        \n",
    "            \"\"\" Final layer with stride s(1 or 2). \"\"\"\n",
    "            self.net.append(f(c, c, k, s, *args))\n",
    "\n",
    "        self.channels.append(c)\n",
    "                \n",
    "    def _calculate_coef(self, phi, alpha=1.2, beta=1.1):\n",
    "        self.d = alpha**phi\n",
    "        self.w = beta**phi\n",
    "\n",
    "    def _update_feat(self, c, l):\n",
    "        return int(c * self.w), int(l * self.d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    stages = [\n",
    "            # [Operator(f), Channels(c), Layers(l), Kernel(k), Stride(s), Expansion(exp)]\n",
    "            [ConvBlock, 32, 1, 3, 2, 1], \n",
    "            [MBConv, 16, 1, 3, 1, 1],\n",
    "            [MBConv, 24, 2, 3, 2, 6],\n",
    "            [MBConv, 40, 2, 5, 2, 6],\n",
    "            [MBConv, 80, 3, 3, 2, 6],\n",
    "            [MBConv, 112, 3, 5, 1, 6],\n",
    "            [MBConv, 192, 4, 5, 2, 6],\n",
    "            [MBConv, 320, 1, 3, 1, 6],\n",
    "            [ConvBlock, 1280, 1, 1, 1, 0]\n",
    "    ]\n",
    "\n",
    "    phis = {\n",
    "            # BX : (phi, resolution, dropout) \n",
    "            \"B0\" : (0, 224, 0.2), \n",
    "            \"B1\" : (0.5, 240, 0.2),\n",
    "            \"B2\" : (1, 260, 0.3),\n",
    "            \"B3\" : (2, 300, 0.3),\n",
    "            \"B4\" : (3, 380, 0.4),\n",
    "            \"B5\" : (4, 456, 0.4),\n",
    "            \"B6\" : (5, 528, 0.5),\n",
    "            \"B7\" : (6, 600, 0.5)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"For output values\"\"\"\n",
    "# def main():\n",
    "#     # User input for model configuration and image path\n",
    "#     model_config = input(\"Enter model configuration (B0, B1, B2, B3, B4, B5, B6, B7): \")\n",
    "#     image_path = input(\"Enter the image path: \")\n",
    "\n",
    "#     # Load and preprocess the image\n",
    "#     config = Config()\n",
    "#     _, res, _ = config.phis[model_config]\n",
    "#     preprocess = transforms.Compose([\n",
    "#         transforms.Resize((res, res)),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "#     ])\n",
    "\n",
    "#     try:\n",
    "#         image = Image.open(image_path).convert(\"RGB\")\n",
    "#     except FileNotFoundError:\n",
    "#         print(f\"Image file not found: {image_path}\")\n",
    "#         sys.exit(1)\n",
    "\n",
    "#     image = preprocess(image).unsqueeze(0)\n",
    "\n",
    "#     # Create the model and pass the image through it\n",
    "#     efficientnet = EfficientNet(model_config)\n",
    "#     efficientnet.eval()  # Set the model to evaluation mode\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         output = efficientnet(image)\n",
    "    \n",
    "#     print(f\"Model output: {output}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # User input for model configuration and image path\n",
    "    model_config = input(\"Enter model configuration (B0, B1, B2, B3, B4, B5, B6, B7): \")\n",
    "    image_path = input(\"Enter the image path: \")\n",
    "\n",
    "    # Load and preprocess the image\n",
    "    config = Config()\n",
    "    _, res, _ = config.phis[model_config]\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize((res, res)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    try:\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Image file not found: {image_path}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    image = preprocess(image).unsqueeze(0)\n",
    "\n",
    "    # Create the model and pass the image through it\n",
    "    efficientnet = EfficientNet(model_config, show=True)\n",
    "    efficientnet.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    with torch.no_grad():\n",
    "        _ = efficientnet(image)\n",
    "    \n",
    "    print(\"Model output summary provided above.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1 ->  [56, 600, 600]\n",
      "Stage 2 ->  [28, 300, 300]\n",
      "Stage 3 ->  [42, 300, 300]\n",
      "Stage 4 ->  [70, 150, 150]\n",
      "Stage 5 ->  [141, 75, 75]\n",
      "Stage 6 ->  [198, 38, 38]\n",
      "Stage 7 ->  [340, 38, 38]\n",
      "Stage 8 ->  [566, 19, 19]\n",
      "Stage 9 ->  [2267, 19, 19]\n",
      "Model output summary provided above.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov7_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
